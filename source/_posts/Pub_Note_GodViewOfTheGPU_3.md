---
title: 上帝视角看GPU（3）：逻辑上的模块划分
---

## 负载平衡问题

![Alt text](image.png)

- 这是一个带有基本的可编程流水线 GPU 的显卡，2003 年的 GeForce FX 5600。
- 它有 2 个 vertex shader 单元，4 个 pixel shader 单元。
- 因此，当顶点和像素的工作量是 1:2 的时候，它能发挥出最高效率。

但这时候 GPU 很容易出现负载不平衡的情况，一部分忙死，另一部分闲死：
![Alt text](image-1.png)

- 一堆很小的三角形挤在一起，顶点很多像素很少，

![Alt text](image-2.png)

- 全屏就一个巨大的三角形，顶点很少像素很多，

![Alt text](image-3.png)

- 另外，随着渲染的内容和流水线越来越复杂，全都堆到硬件上，负载平衡出问题只会是早晚的事情。

## 统一 shader 架构

vertex shader 单元和 pixel shader 单元有什么不同呢？
在 2005 年以前：
![Alt text](image-4.png)

- vertex shader 需要做 32 位浮点精度的计算，因为坐标需要有那么高的精度，但是不需要读取纹理。
- 而 pixel shader，基本只和颜色打交道，精度不用太高，但是需要读取纹理。

但随着需求的发展，它们的界限逐渐变得模糊：

![Alt text](image-5.png)

- 大规模地形渲染的需求，使得 vertex shader 得能读取纹理。

![Alt text](image-6.png)

- 用 pixel shader 做通用计算的需求，使得 pixel shader 也需要 32 位浮点精度的支持。

![Alt text](image-7.png)

- 结果就是两个单元都有一样的纹理采样器，以及一样的运算器。

![Alt text](image-8.png)

- 于是大家发现可以用同样的硬件单元来执行各种 shader，这叫做统一 shader 架构，unified shader architecture。

那么，什么时候执行 vertex shader 什么时候执行 pixel shader 呢？
![Alt text](image-9.png)
![Alt text](image-10.png)

- 通过调度器来动态分配，这样负载平衡的问题就被解决了。
- 同时 GPU 硬件也可以因为共享而变得简单一致。

![Alt text](image-11.png)

- 一般来说，一个 shader 里纹理采样的次数远低于计算，所以采样器的数量可以少于运算器。
- 因此可以拆出来共享，交给调度器去分配。其他固定流水线单元，也都可以这样来安排。

这是 GeForce RTX 3090 Ti 包含的 shader 核、采样器、光栅化和像素操作单元的数量：
![Alt text](image-12.png)

- 即便有那么多类型的 shader，但硬件的执行单元都是一样的。

## GPU 核

我们经常可以听到 GPU 动不动就是成千上万个核，而 CPU 能有几十个核就了不起了，GPU 真的有那样惊人的核数吗？
![Alt text](image-13.png)

- 主要还是因为它们对“核”的定义不同。

这里先要介绍一下两个计算机体系结构的概念：
![Alt text](image-14.png)

- 单指令单数据流 SISD
- 单指令多数据流 SIMD。

我们做这样一个类比：
![Alt text](image-15.png)

- 指令类比于红绿灯，数据类比于车，数据流类比于路面。

![Alt text](image-16.png)

- 在 SISD 里，每条公路就一个车道，一个红绿灯控制路上车辆的走向。

![Alt text](image-17.png)

- 而在 SIMD 里，有多个车道，共享同一个红绿灯
- 路上的车走向必须一致。

![Alt text](image-18.png)

- CPU 上的一个核是 SISD 的，带有一定的 SIMD 指令集作为补充。
- 比如 SSE 指令集，可以对 4 个数做同样的操作，相当于 4 车道。
- 现在的 AVX-512 指令集，宽度到了 16。

![Alt text](image-19.png)

- 现在的 GPU 都至少是 SIMD 的，而且宽度很大，有 16、32、64、甚至 128 的。
- GPU 上的一个核，指的只是 SIMD 里的一条通路，也就是一个车道。
- 逻辑上可以认为这么多个 GPU 线程在同一个时刻总是执行同样的指令。
- 这样的一组线程称为 warp 或者 wave。

![Alt text](image-20.png)

- 如果采用 GPU 的核的定义（车道），CPU 的核数至少要乘上 SSE 的宽度 4。
- 反过来，如果采用 CPU 的核的定义（路），GPU 的核数至少要除掉 warp 的宽度。

![Alt text](image-22.png)

- GPU 的核，称为流处理器，streaming processor（SP）。
- 一组 SP，加上控制器和片上内存等，成为一个功能相对完整的 streaming multi-processor（SM）。

![Alt text](image-21.png)

- NVIDIA 的 RTX 30 系列 GPU，一个 SM 包含 128 个 SP，4 个采样器。
- 一堆 SM 成了 GPU 上的主要组成部分。
- 而所谓的切一刀，就是指同系列的不同款 GPU，SM 数量有所不同（难怪老黄刀法那么精准）。
- 高端的 3090 Ti 有 84 个 SM，低端的 3050 就切到了 20 个。

## SIMD 的问题

CPU 和 GPU 的第三个大区别，数据流宽度：

- GPU 的 SIMD 很宽，大部分晶体管都用于运算，少量用于控制。

但也存在一些问题：

如果有 32 个车道，但总是只有两三辆车在路上跑，那么道路就被浪费了。

- 这需要靠软件方面来解决，拿尽量多的任务去塞满所有车道。

32 个车道必须都执行同样的操作，要么全都直行，要么全都左拐。但如果 32 辆车里有的要直行，有的要左拐怎么办？

![Alt text](image-24.png)

- 在 SISD 的时候，x、a、b、c 都是标量。根据 x 的值来决定 a 是相加还是相乘就行了。
- 但如果是宽度为 32 的 SIMD 的情况，这时候 x、a、b、c 分别对应宽度 32 的向量里的一个分量。
- 如果 x 的每个分量都一样，那还好办，GPU 只要执行一个分支。这时候分支造成的开销可以忽略不计。
- 但如果这 32 个车道的 x 并不相同，就产生了分支分歧。

![Alt text](image-23.png)

- 为了保证 SIMD，也就是控制流的一致性，就得把代码展开成这样。
- select 是一个 SIMD 的选择操作，可以根据 x 向量里每一个分量选择从 a1 还是 a2 提取一个分量。
- 也就是说，SIMD 展开会导致两个分支都执行，每个分量从结果里选择一个，抛弃另一个，造成了计算浪费。

这个浪费一方面增加了时间，另一方面增加了功耗。

![Alt text](image-25.png)

- 为了改进这个缺点，用到了一些 MIMD 的思想。

![Alt text](image-26.png)

- 传统的 MIMD，相当于让每个车道都有自己的红绿灯，左拐的左拐，直行的直行，同时完成，没有浪费。
- 但这样复杂度高了很多，往往得不偿失。

NVIDIA 在 GPU 上做 MIMD，用了一个取巧的方式：
![Alt text](image-27.png)
![Alt text](image-28.png)

- 同样每个车道有单独的红绿灯。
- 当直行的时候，左拐的车道亮红灯。轮到左拐的时候，直行车道亮红灯。

这样虽然仍然会花费两倍执行的时间，但是没有计算的浪费，功耗降下来了，硬件复杂性却不会增加多少。

## 计算掩盖访存

![Alt text](image-29.png)

- GPU 的计算是宽的，因此内存也得跟得上。独立显卡有自己的内存，称为显存。
- 对应的 CPU 这边的内存就称为主存。

![Alt text](image-30.png)

- 常见显存的类型是 GDDR，硬件位宽是 128-512 位，高于主存 DDR 的 32-64 位。

为了一次读写很宽的数据，显存被设计成用高延迟换取高吞吐量。

- 延迟往往在百纳秒这个数量级，比主存高很多。
- 当需要读取显存的数据时，它得等成团之后再一批发给你。但如果就这么等着，会严重影响 GPU 的执行效率。

这里再次用调度的思想来解决这个问题：
![Alt text](image-31.png)

- 以一个简单的程序为例，先执行一些计算，再读取内存，再执行一些计算。
- 当一个 warp 执行到 Read()的时候，需要等上一阵子才能拿到结果。
- SM 里边有个组件叫 warp 调度器，可以把这个 warp 暂停下来，激活下一个 warp 来执行，下个 warp 到了 Read()，再暂停，再激活下一个 warp 执行，如此反复。
- 如果最早被暂停的 warp 已经完成了读取，就又被激活，继续往下执行。

![Alt text](image-32.png)

- 这称为用计算掩盖访存（compute hides memory latency）。
- 这样的调度使得 GPU 的线程数量可以远远大于核的数量。

![Alt text](image-33.png)

- SM 内部会有一个寄存器空间，每个 warp 都会占用一部分用于局部变量等。
- 要是整个空间都占满了就没法再调度更多的 warp 进来，只能真的停下来等内存读取。
- 这就是访存实在无法被计算掩盖的情况，会降低效率，需要修改算法或数据大小来减少访存才能优化上去。

![Alt text](image-34.png)

- CPU 上的超线程，也使用了类似的思路，通过调度把局部单元尽量占满，使得硬件线程数可以高于核数。

![Alt text](image-35.png)

- CPU 和 GPU 的第四个大区别：CPU 计算的延迟小，GPU 计算的吞吐量大。
- CPU 相当于一辆轿车。上车就开，直奔目的地，但一趟运不了几个人。
- 而 GPU 相当于一辆公交车，得花很多时间上人，每一站还得停。但一趟能把很多人送到目的地。

![Alt text](image-36.png)

- GPU 可以大量使用计算掩盖访存，对 cache 的要求小了很多。
- 而 CPU 为了降低访存的延迟，需要很大的芯片面积做多级 cache。
- cache 的功耗很大，因此 GPU 的这种设计也能进一步降低功耗。

## 补充

- [GPU 中的 SM 和 warp 的关系](https://blog.csdn.net/feng__shuai/article/details/108401793)
- [基本概念：线程块（Thread Block）与 Warp 的区别、SM、Grid、Dimension](https://blog.csdn.net/m0_63471305/article/details/139839856)

SM 和 warp 的关系：

- SM 是 GPU 中的一个基本的硬件组件
- 而 warp 是 GPU 中的一个基本的调度单元，也就是我们前面说的有多个并行车道的道路。
- 一个线程块（Thread Block）由多个线程组成，这些线程可以在执行过程中协作。线程块中的线程可以通过共享内存进行通信，并使用同步原语进行同步。
- 一个线程块由若干个 warp 组成。例如，如果一个线程块包含 256 个线程，那么这个线程块将被划分为 8 个 warp（256/32 = 8）。这种划分是由硬件自动完成的，程序员不需要手动管理 warp。
- 线程块是程序员定义的逻辑分组，一个线程块的多个 warp 可以在同一个 SM 上同时执行，也可以分时复用 SM 的资源。
